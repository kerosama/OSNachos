============================================================================================================================================================================================================================================================================
I. Requirements
======================================================================================================================================
======================================================================================================================================
Part 1:
Implement the TLB. Any program must be able to run to completion with the proper output, using the TLB to store pages when they are used. 
This includes the following:
1. Creating a TLB structure
2. Replacing all of the machine->pageTable references with the TLB
3. Invalidating TLB entries on context switch
4. Using FIFO to replace TLB pages on pagefaults

Part 2: 
Implement virtual memory. Everything that worked previously must work without the assumption of unlimited physical pages.
This includes the following:
1. Setting the maximum number of physical pages to 32. 
2. Creating the IPT
3. Checking the IPT for a page with the needed virtual page number upon a pageFaultException 
4. Retrieving the page data on an IPT hit and transferring it to the TLB and the current address space pageTable
5. Populating IPT with needed page on an IPT miss
6. Reading from the address space executable for virtual memory that has not previously been accessed
7. Evicting pages from the IPT when full
6. Writing dirty, evicted pages to a swapfile and updating the disk location for the corresponding page in the address space pageTable
7. Reading from a swapfile when a needed virtual page corresponds to a pageTable entry with its disk location in the swap file
8. Updating the TLB whenever the IPT is updated
9. Preventing race conditions when reading or writing to shared data, namely the TLB, IPT, pageTables, and main memory
10. Invalidating the pages of the IPT owned by the current process when a thread finishes
11. Clearing the swap file when the last thread has exited

Part 3: 

Implementation for remote procedure calls for the Lock and Condition Variable system calls in Project 2, and new system calls for handling monitor variables. 

Part 3 simulates a networking system that handles both the client and server sides. The process begins with a client making a request out to the server for a particular system call. Upon receiving, the server handles the request and provides an ID that enables access each individual request from clients. The implementation in client has been handled so that a user program can make a request and a system call in client would transmit the request to the server. 

Server is a system made up of a single thread, running in a never-ending loop to retrieve any incoming requests. Client is a machine which sends a request to the server and waits for its response. Condition variables, monitor variables, and locks are to be implemented conceptually rather than physically remotely, since the threads are running on different systems, allocating their address space on various machines.

======================================================================================================================================
======================================================================================================================================
II. Assumptions
======================================================================================================================================
======================================================================================================================================

Part 1: 
• The translation files handle valid bits properly for TranslationEntry
• Page Tables inside AddrSpace function properly
• All of the syscalls from Project 2 function properly
• Unlimited physical pages

Part 2:
• The swap file can be placed inside the vm directory

Part 3:
• Post office runs accordingly
• Mailboxes are set up to function accordingly
• Messages are sent correctly through post office

======================================================================================================================================
======================================================================================================================================
III. Design
======================================================================================================================================
======================================================================================================================================
Part 1:

Handling page faults (with physical memory):
Before the existence of the IPT or swapfile, all virtual memory was preloaded into main memory through the addrSpace constructor.
All that had to be done at this point was replacing pages in the TLB using FIFO and getting the proper information from the page table in the current address space.

Below is the handlePageFault function by the completion of this step:

void handlePageFault()
{	
	int neededVA = machine->ReadRegister(BadVAddrReg);
	int neededVPN = neededVA / PageSize;
		
	IntStatus oldLevel = interrupt->SetLevel(IntOff);   
	machine->tlb[currentTLB].physicalPage = currentThread->space->pageTable[neededVPN].physicalPage;
	machine->tlb[currentTLB].virtualPage = neededVPN;
	machine->tlb[currentTLB].valid = true;
	machine->tlb[currentTLB].use = false;
	machine->tlb[currentTLB].dirty = false;
	machine->tlb[currentTLB].readOnly = false;			
	(void) interrupt->SetLevel(oldLevel);

	currentTLB = (currentTLB + 1) % TLBSize; //Increment TLB page number for FIFO
}

Also, in the RestoreState function in AddrSpace, the TLB pages were invalidated.

void AddrSpace::RestoreState() 
{	
	IntStatus oldLevel = interrupt->SetLevel(IntOff); 
		
	for (int a = 0; a < TLBSize; a++)
	{
		//transfer dirty bits from tlb to ipt
		//only pass dirty bit if tlb page is still valid
		if(machine->tlb[a].valid == true)
		{
			for(int i = 0; i < NumPhysPages; i++)
			{
				//if tlb page's virtual page is in the tlb, transfer dirty bits
				if(mIPT->ipTable[i].virtualPage == machine->tlb[a].virtualPage)
				{	
					printf("Transferred dirty bit from tlb page %d to IPT page %d (VPN: %d)\n", a, i, machine->tlb[a].virtualPage);				
					mIPT->ipTable[i].dirty = machine->tlb[a].dirty;
				}
			}
		}
	
		//invalidate tlb page because of context switch
		printf("Invalidated tlb page %d", a);
		machine->tlb[a].valid = false;		
	}
	
	(void) interrupt->SetLevel(oldLevel);
}

Note: The page table population and preloaded memory in the AddrSpace constructor have not yet changed since project 2. 

Part 2:
IPTEntry is the same as TranslationEntry, except it has a pointer to the address space that owns it.
It is a class defined in threads/system.

class IPTEntry : public TranslationEntry 
{
	 public:
		AddrSpace* owner;
};

The IPT class is the IPT data structure, having an array of IPTEntries of size NumPhysPages.
It is a class defined in threads/system.

class IPT
{
	public:
		IPT();
		~IPT();
		IPTEntry* ipTable;

};

The following are variables defined in threads/system, for global use:

BitMap *mmBitMap
A pointer to the bitmap for the IPT, containing 32 bits, the same as the number of physical pages in the IPT
		
IPT *mIPT;
A pointer to the IPT, shared by all of the processes

OpenFile *swapFile;
A pointer to the file that contains dirty, evicted pages

BitMap *swapMap;
A pointer to the bitmap for the swap file, which determines where pages get written to the swap file

Lock *memoryLock;
A pointer to the lock that enables mutual exclusion when writing to or reading from main memory

Lock *iptLock;
A pointer to the lock that enables mutual exclusion when writing to or reading from the IPT

Lock *swapLock;
A pointer to the lock that enables mutual exclusion when writing to or reading from the swapFile

The following are new variables in the AddrSpace class:

OpenFile *spaceExec
A pointer to the executable passed through the AddrSpace constructor. 
The executable needed to be stored for this part of the project because virtual memory could no longer be preloaded.



class PTE : public TranslationEntry
{
	public:
		//location of a page table entry's data on disk (-1 if in executable (code), 0 if in executable (init data), 1 if swapfile, 2 if neither (uninit data))
		int diskLocation 
		//position respective to disk location
		int byteOffset;
};
A modified TranslationEntry

Handling page faults (with virtual memory):



IMPORTANT NOTE FOR GRADING!!!!

There are some minor issues when NumPhysPages in machine is set to 32. It mostly works, but there are some arbitrary halts.
We suspect it has something to do with occasional lost data. FIFO and RAND produce distinct errors.
Everything works when NumPhysPages is large. Please set it to 1024 to test program outputs. Every test case works.

IMPORTANT NOTE FOR GRADING!!!!



The addrspace constructor has been modified. Pagetables now have extra properties, which are explained later in this document.

AddrSpace::AddrSpace(OpenFile *executable) : fileTable(MaxOpenFiles) {
	NoffHeader noffH;
    unsigned int i, size;

	PTLock = new Lock("Page Table Lock");
    // Don't allocate the input or output to disk files
    fileTable.Put(0);
    fileTable.Put(0);

	spaceExec = executable;
	//printf("creating new addrSpace");
    executable->ReadAt((char *)&noffH, sizeof(noffH), 0);
    if ((noffH.noffMagic != NOFFMAGIC) && 
		(WordToHost(noffH.noffMagic) == NOFFMAGIC))
    	SwapHeader(&noffH);
    ASSERT(noffH.noffMagic == NOFFMAGIC);

    size = noffH.code.size + noffH.initData.size + noffH.uninitData.size ;
	
	printf("Code Size: %d, Init Data Size: %d, Uninit Data Size: %d, Page Size: %d, Total Size: %d\n", noffH.code.size, noffH.initData.size, noffH.uninitData.size, PageSize, size);
    numPages = divRoundUp(size, PageSize) + divRoundUp(UserStackSize,PageSize);
                                                // we need to increase the size
						// to leave room for the stack
    size = numPages * PageSize;

	PageTable = new PTE[numPages];

   // ASSERT(numPages <= NumPhysPages);		// check we're not trying
						// to run anything too big --
						// at least until we have
						// virtual memory

    DEBUG('a', "Initializing address space, num pages %d, size %d\n", 
					numPages, size);
	
	PTLock->Acquire("");
	for(int i =0 ; i < numPages; i++)
	{
		PageTable[i].virtualPage = i;
		PageTable[i].physicalPage = -1; //initially set without physical page
					
		PageTable[i].byteOffset = PageTable[i].virtualPage*PageSize + noffH.code.inFileAddr;

		int loc = i*PageSize; 
		if(loc < noffH.code.size)
		{
			//Page is in the executable code and will never change
			printf("Code page %d\n", i);
			PageTable[i].diskLocation -1;
		}
		else if(loc < (noffH.code.size + noffH.initData.size))
		{
			//Page is in the executable data but can be changed
			printf("Init data page %d\n", i);
			PageTable[i].diskLocation = 0;
		}
		else
		{
			//Page is uninitialized and not in executable
			printf("Uninit data page %d\n", i);
			PageTable[i].diskLocation = 2;
		}

	}
	PTLock->Release("");

}


Also, AddPages() in addrspace, which is used when forking, has been modified. 

void AddrSpace::AddPages()
{
	//Add 8 pages to page table
	PTLock->Acquire("");
	PTE* tempTable = new PTE[numPages + 8];
	for(unsigned int i = 0; i < numPages; i++)
	{
		
		tempTable[i].virtualPage = PageTable[i].virtualPage;	
		tempTable[i].physicalPage = PageTable[i].physicalPage;
		//tempTable[i].valid = PageTable[i].valid;
		//tempTable[i].use = PageTable[i].use;
		//tempTable[i].dirty = PageTable[i].dirty;
		//tempTable[i].readOnly = PageTable[i].readOnly;

		//copy new values for PTE structure
		tempTable[i].byteOffset = PageTable[i].byteOffset;
		tempTable[i].diskLocation = PageTable[i].diskLocation;
	}

	delete PageTable;
	PageTable = tempTable;

	for(unsigned int i = numPages; i < (numPages + 8); i++)
	{
		
		PageTable[i].virtualPage = i;
		PageTable[i].physicalPage = -1;
		PageTable[i].valid = FALSE;
		PageTable[i].use = TRUE;
		PageTable[i].dirty = FALSE;
		PageTable[i].readOnly = FALSE; 

		printf("here");
		//new values for pagetable PTE structure
		PageTable[i].byteOffset = 0;
		PageTable[i].diskLocation = 2;
		//PageTable[i].diskLocation.position = PageTable[i].virtualPage;
	}

	numPages += 8;
	PTLock->Release("");
}


Before the current TLB page is replaced, the page with the needed virtual memory must be found inside the IPT, rather than the current
address space's page table.
First, a variable ppn is declared and initialized to -1, which is not a physical page number. 
It is to be replaced with the desired physical page number eventually.
The first attempt to find the physical page number is by verifying that one of the 32 entries in the IPT has the matching virtual page number,
is owned by the current address space, and is valid. In that case, it is an IPT hit.

void handlePageFault()
{	
	int neededVA = machine->ReadRegister(BadVAddrReg);
	int neededVPN = neededVA / PageSize;

	printf("Needed VPN: %d\n", neededVPN);

	int ppn = -1;
		
	iptLock->Acquire("");
	for(int i = 0; i < NumPhysPages; i++)
	{
		if(mIPT->ipTable[i].virtualPage == neededVPN)
		{
			if(mIPT->ipTable[i].owner == currentThread->space)
			{
				if(mIPT->ipTable[i].valid == true)
				{
					//IPT hit
					//wanted physical page is IPT index number
					printf("IPT hit for virtual page %d\n", neededVPN);
					ppn = i;
					break;
				}
			}
		}
	}
	iptLock->Release("");

	//IPT miss
	if(ppn == -1)
	{		
		ppn = handleIPTMiss(neededVPN);
	}
	
	
	//Last step: update TLB
	//Need to disable interrupts	
	IntStatus oldLevel = interrupt->SetLevel(IntOff); 
	if(ppn != -1)
	{
		//transfer dirty bits from replaced tlb page if still valid
		for(int i = 0; i < NumPhysPages; i++)
		{
			if(machine->tlb[currentTLB].valid == true /*&& machine->tlb[currentTLB].dirty == true*/ && mIPT->ipTable[i].virtualPage == machine->tlb[currentTLB].virtualPage)
			{
				printf("Transferred dirty bit from tlb page %d to IPT page %d (VPN: %d)\n", currentTLB, i, machine->tlb[currentTLB].virtualPage); 
				mIPT->ipTable[i].dirty = machine->tlb[currentTLB].dirty;
			}
		}
	
		machine->tlb[currentTLB].physicalPage = ppn;
		machine->tlb[currentTLB].virtualPage = neededVPN;
		machine->tlb[currentTLB].valid = true;
		machine->tlb[currentTLB].dirty = mIPT->ipTable[ppn].dirty;		
		
	}
	else
	{
		printf("Error: could not provide physical page to TLB");
	}

	currentTLB = (currentTLB + 1) % TLBSize; //Increment TLB page number for FIFO
	(void) interrupt->SetLevel(oldLevel);

}

Otherwise, it is an IPT miss, and the next resort is to call the handleIPTMiss function, which provides a physical page for the needed virtual address.
Inside this function, the IPT bitmap is searched for a free entry. 
If there is no free entry, a page will be evicted in the handleMemoryFull function.
Otherwise, all of the pages in the address space pagetable are checked for a matching virtual page, and if a match is found, the data
corresponding to the page in virtual memory gets retrieved from the executable or swapfile, depending on the DiskLocation of the page, and written into main memory. 

int handleIPTMiss(int neededVPN)
{
	int ppn = mmBitMap->Find();
	if(ppn == -1)
	{
		ppn = handleMemoryFull(neededVPN);
	}	

	//Get location of virtual page from current space pagetable
	//Get data from virtual page from swap file or executable
	currentThread->space->PTLock->Acquire("");
	for(int j = 0; j < currentThread->space->numPages; j++)
	{
		if(currentThread->space->PageTable[j].virtualPage == neededVPN)
		{
			if(currentThread->space->PageTable[j].diskLocation == 1)
			{
				memoryLock->Acquire("");
				
				int pg = currentThread->space->PageTable[j].byteOffset/PageSize;
				printf("Reading from swapfile page %d to main memory...\n", pg);
				swapFile->ReadAt(&machine->mainMemory[ppn*PageSize], 
					PageSize, currentThread->space->PageTable[j].byteOffset);

				//clear the page in swapfile bitmap
				swapMap->Clear(currentThread->space->PageTable[j].byteOffset/PageSize);

				//came from swap file, so it's dirty
				mIPT->ipTable[ppn].dirty = true;

				//no longer in swapfile or executable
				currentThread->space->PageTable[j].diskLocation = 2;
				memoryLock->Release("");
			}
			else if(currentThread->space->PageTable[j].diskLocation == 0)
			{
				memoryLock->Acquire("");
				currentThread->space->spaceExec->ReadAt(&machine->mainMemory[ppn*PageSize], 
					PageSize, currentThread->space->PageTable[j].byteOffset);
				printf("Reading from executable virtual page %d to main memory...\n", currentThread->space->PageTable[j].virtualPage);
				//if(j != 0)
				//{
					currentThread->space->PageTable[j].diskLocation = 2;
				//}
				
				mIPT->ipTable[ppn].dirty = false;
				memoryLock->Release("");
			}
			else
			{
				mIPT->ipTable[ppn].dirty = false;
			}
			currentThread->space->PageTable[j].physicalPage = ppn;
			
			iptLock->Acquire("");
			mIPT->ipTable[ppn].owner = currentThread->space;
			mIPT->ipTable[ppn].virtualPage = neededVPN;
			mIPT->ipTable[ppn].valid = true;
			
			iptLock->Release("");
			break;
		}
	}	
	currentThread->space->PTLock->Release("");	

	return ppn;
}

Lastly, if the IPT is already full, a page must be evicted by selecting a random page to evict or by using FIFO, which is specified in the command line.
When a page is evicted, it is checked whether it is dirty. If it is dirty, it is written to the swap file using the WriteToSwap function, in which the dirty memory is written into the swap file.

int handleMemoryFull(int neededVPN)
{
#ifdef NETWORK
	isFIFO = true;
#else
	isFIFO = false;
#endif
	int evictedPageNum = -1;
	isFIFO = true;
	//If isFIFO is true, use FIFO to evict page. Otherwise, use random page selection.
	if(isFIFO)
	{
		//evict the page added the earliest, which is stored in currentIPT
		evictedPageNum = (currentIPT + 1) % NumPhysPages;
		currentIPT = evictedPageNum;
		//printf("currentIPT: %d\n", currentIPT);
	}
	else
	{
		//randomly determine an IPT page to evict
		do 
		{
			srand(time(NULL));
			evictedPageNum = rand() % NumPhysPages;
		}while(evictedPageNum == currentIPT);
		currentIPT = evictedPageNum;
	}

	mIPT->ipTable[evictedPageNum].valid = false;

	iptLock->Acquire("");
	if(mIPT->ipTable[evictedPageNum].dirty == true)
	{
		iptLock->Release("");
		WriteToSwap(evictedPageNum);
	}
	else
	{
		iptLock->Release("");
		
		//Check if evicted page already exists in TLB
		//If it is in TLB, check if the page is dirty
		//If the page is dirty, find the physical page in the current process pagetable
		//If the page exists in the pagetable, write the dirty page to an available spot in the swapfile, using the physical page number
		
		//Need to disable interrupts for TLB access				  
		IntStatus oldLevel = interrupt->SetLevel(IntOff); 
		for(int i = 0; i < TLBSize; i++)
		{			
			if(machine->tlb[i].physicalPage == evictedPageNum)
			{
				if(machine->tlb[i].dirty == true)
				{
					WriteToSwap(evictedPageNum);

					break;
				}
			}
		}	
		(void) interrupt->SetLevel(oldLevel);
		
	}

	//need to give IPT page to replace
	return evictedPageNum;
}

void WriteToSwap(int epn)
{
	iptLock->Acquire("");
	currentThread->space->PTLock->Acquire("");
	for(int j = 0; j < mIPT->ipTable[epn].owner->numPages; j++)
	{
		
		if(currentThread->space->PageTable[j].physicalPage == epn)
		{
			int swapPage;
			if(mIPT->ipTable[epn].owner->PageTable[j].diskLocation != 1)
			{
				swapPage = swapMap->Find();
				if(swapPage == -1)
				{
					printf("Error: swapfile full\n");
					return;
				}
				
				mIPT->ipTable[epn].owner->PageTable[j].diskLocation = 1;
				swapPage = swapPage*PageSize;
				mIPT->ipTable[epn].owner->PageTable[j].byteOffset = swapPage;

			}
			else
			{
				swapPage = mIPT->ipTable[epn].owner->PageTable[j].byteOffset;
			}
			
			memoryLock->Acquire("");
			swapFile->WriteAt(&machine->mainMemory[epn*PageSize], PageSize, swapPage);
			memoryLock->Release("");	


			//mIPT->ipTable[epn].owner->PageTable[j].physicalPage = -1;
			//mIPT->ipTable[epn].owner->PageTable[j].valid = false;
			//mIPT->ipTable[epn].valid = false;
			printf("added physical page %d from virtual page %d to swapfile page %d\n", epn, j, swapPage/PageSize);
			break;
		}
	}	
	iptLock->Release("");
	currentThread->space->PTLock->Release("");
}

In addition to these new implementations, there were changes to Part 1.
The AddrSpace::RestoreState function, now looks like this:

void AddrSpace::RestoreState() 
{	
	IntStatus oldLevel = interrupt->SetLevel(IntOff); 
	for (int a = 0; a < TLBSize; a++)
	{
		machine->tlb[a].valid = false;
		if(machine->tlb[a].dirty == true)
			
			for(int i = 0; i < numPages; i++)
			{
				if(i == PageTable[i].physicalPage)
				{					
					mIPT->ipTable[i].dirty = true;
			}
		}		
	}	
	(void) interrupt->SetLevel(oldLevel);
}

In the Exit syscall, the IPT pages belonging to the terminated thread's process are invalidated.
In addition, the swapfile is cleared when all threads are terminated.
The Exit syscall now looks like this:

void Exit_Syscall(int status) {
	// If there are other threads, finish the thread, otherwise call halt
	// and stop the user program.
	printf("Output: %d\n", status);
	if (num_thr > 0) {
		num_thr--;

		//invalidate ipt entries for this space
		iptLock->Acquire("");
		for(int i = 0; i < NumPhysPages; i++)
		{
			if(mIPT->ipTable[i].owner == currentThread->space)
			{
				mIPT->ipTable[i].valid = false;
			}
		}
		iptLock->Release("");

		currentThread->Finish();		
	}
	else
	{
		//clear the swapfile
		char buf[PageSize];
		memset(buf, ' ', PageSize);
		for(int i = 0; i < SWAP_SIZE; i++)
		{			
			swapFile->WriteAt(buf, PageSize, i*PageSize);
		}
		//end program
		interrupt->Halt();
	}
}


Part 3:
System call handler utilizes the system call implement in the client system to send a request to server.
Upon receiving, the server parses the message of the request and processes it accordingly. 

struct ServerLock{
    int ownerOfLock;
    int inUse;
    char* nameOfLock;
    bool toBeDeleted;

    List* destMachineIDQueue;
    List* msgQueue;
    LockStatus lockStatus;
};
int lockServerIDAdder = 0;
ServerLock lockServerList[LOCKS_MAX_COUNT];

struct ServerCV{
    int waitLock;
    int inUse;
    int waitQueueCount;
    char *nameOfCV;
    bool toBeDeleted;

    List *msgQueue;
    List *destMachineIDQueue; 
};
int cvServerIDAdder = 0;
ServerCV cvServerList[CV_MAX_COUNT];

struct ServerMV{
    int size;
    //int* mv;
	int mv;
    int inUse;

    char* nameOfMV;
};
int mvServerIDAdder = 0;
ServerMV mvServerList[MV_MAX_COUNT];

——————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————

I. 
createServerLock(lockName, idOfMachine){
    int lenOfName;
    lenOfName = strlen(lockName);

    for(int i = 0; i < lockServerIDAdder; i++){
        if(lockServerList[i].nameOfLock != NULL){
            if(strcmp(lockServerList[i].nameOfLock, lockName) == 0){
                sprintf(ack,"%d",i);
		lockServerList[i].inUse++;
                return;
            }
        }
    }

    if(lockServerIDAdder >= LOCKS_MAX_COUNT){
        strcpy(ack,"-1");
        return;
    }

    lockServerList[lockServerIDAdder].ownerOfLock = 0;
    lockServerList[lockServerIDAdder].inUse = 1;
    lockServerList[lockServerIDAdder].toBeDeleted = false;

    lockServerList[lockServerIDAdder].destMachineIDQueue = new List;
    lockServerList[lockServerIDAdder].msgQueue = new List;
    lockServerList[lockServerIDAdder].lockStatus = FREE;

    lockServerList[lockServerIDAdder].nameOfLock = new char[40];
    strcpy(lockServerList[lockServerIDAdder].nameOfLock,lockName);

    sprintf(ack,"%d",lockServerIDAdder++);

    return;
}

II.
acquireServerLock(idOfLock, idOfMachine){
	if (idOfLock < 0 || idOfLock > lockServerIDAdder)
	{
		strcpy(ack, "-1");
		return 1;
	}

	if (lockServerList[idOfLock].lockStatus == FREE){
		lockServerList[idOfLock].ownerOfLock = idOfMachine;
		lockServerList[idOfLock].lockStatus = BUSY;
	}

	else{
		msg = new char[70];
		strcpy(msg, "clientmsg");

		toAddress = new int;
		*toAddress = idOfMachine;

		lockServerList[idOfLock].destMachineIDQueue->Append((void *)toAddress);
		return 0;
	}

	strcpy(ack, "1");
	return 1;
}

III.
releaseServerLock(idOfLock, int idOfMachine){
	if (idOfLock < 0 || idOfLock > lockServerIDAdder)
	{
		strcpy(ack, "-1");
		return 1;
	}

	if (!(lockServerList[idOfLock].msgQueue->IsEmpty())){
		char *pointerMsg;
		int *pointerMachineID;
  
		pointerMsg = (char *)lockServerList[idOfLock].msgQueue->Remove();
		pointerMachineID = (int *)lockServerList[idOfLock].destMachineIDQueue->Remove();

		strcpy(ack, "1");
		outPktHdr.to = *pointerMachineID; //location                          
		outMailHdr.to = *pointerMachineID;
		outMailHdr.from = 0;
		outMailHdr.length = strlen(ack) + 1;

		postOffice->Send(outPktHdr, outMailHdr, ack);
	}
	else{
		lockServerList[idOfLock].ownerOfLock = 0;
		lockServerList[idOfLock].lockStatus = FREE;
	}

	strcpy(ack, "1");
	return 1;
}

IV.
destroyServerLock(idOfLock, idOfMachine){
	if (idOfLock < 0 || idOfLock > lockServerIDAdder)
	{
		strcpy(ack, "-1");
		return;
	}
	if (!(lockServerList[idOfLock].msgQueue->IsEmpty())){
		lockServerList[idOfLock].toBeDeleted = true;
		strcpy(ack, "1");
		return;
	}
	lockServerList[idOfLock].inUse--; 

	if (lockServerList[idOfLock].inUse == 0){
		lockServerList[idOfLock].ownerOfLock = 0;
		lockServerList[idOfLock].nameOfLock = NULL;

		delete lockServerList[idOfLock].msgQueue;
		delete lockServerList[idOfLock].destMachineIDQueue;
	}

	strcpy(ack, "1");
	return;
}

V.
CreateCV(nameOfCondition, idOfMachine){
	int lenOfName;
	lenOfName = strlen(nameOfCondition);

	for (int i = 1; i < cvServerIDAdder; i++){
		if (cvServerList[i].nameOfCV != NULL){
			if (strcmp(cvServerList[i].nameOfCV, nameOfCondition) == 0){
				sprintf(ack, "%d", i);
				cvServerList[i].inUse++;
				return;
			}
		}
	}

	if (cvServerIDAdder >= CV_MAX_COUNT){
		strcpy(ack, "-1");
		return;
	}

	cvServerList[cvServerIDAdder].inUse = 1;
	cvServerList[cvServerIDAdder].toBeDeleted = false;
	cvServerList[cvServerIDAdder].waitQueueCount = 0;

	cvServerList[cvServerIDAdder].destMachineIDQueue = new List;
	cvServerList[cvServerIDAdder].msgQueue = new List;
	cvServerList[cvServerIDAdder].waitLock = -1;

	cvServerList[cvServerIDAdder].nameOfCV = new char[50];

	strcpy(cvServerList[cvServerIDAdder].nameOfCV, nameOfCondition);

	sprintf(ack, "%d", cvServerIDAdder);
	cvServerIDAdder++;

	return;
}

VI.
DestroyCV(idOfCondition, idOfMachine){
	if (idOfCondition < 0 || idOfCondition > cvServerIDAdder)
	{
		strcpy(ack, "-1");
		return 1;
	}
	if (!(cvServerList[idOfCondition].msgQueue->IsEmpty())){
		cvServerList[idOfCondition].toBeDeleted = true;
		strcpy(ack, "1");
		return 1;
	}
	cvServerList[idOfCondition].inUse--; 

	if (cvServerList[idOfCondition].inUse == 0){
		cvServerList[idOfCondition].waitQueueCount = -1;
		cvServerList[idOfCondition].waitLock = -1;
		cvServerList[idOfCondition].nameOfCV = NULL;

		delete cvServerList[idOfCondition].msgQueue;
	}

	strcpy(ack, "1");
	return 1;
}

VII.
WaitCV(conditionID, lockID, idOfMachine){
	if (conditionID < 0 || conditionID > cvServerIDAdder ||
		lockID < 0 || lockID > lockServerIDAdder)
	{
		strcpy(ack, "-1");
		return 1;
	}

	int index = 0;

	if (cvServerList[conditionID].waitLock == -1)
		cvServerList[conditionID].waitLock = lockID;
	else
	{
		printf("WaitCV: Lock being waited on.");
		strcpy(ack, "-1");
		return 1;
	}

	releaseServerLock(lockID, idOfMachine);

	msg = new char[70];
	strcpy(msg, "clientcvmsg");
	toAddress = new int;
	*toAddress = idOfMachine;

	cvServerList[conditionID].msgQueue->Append((void *)msg);               
	cvServerList[conditionID].destMachineIDQueue->Append((void *)toAddress);              

	return 0;
}

VIII.
SignalCV(conditionID, lockID, idOfMachine){

	if (conditionID < 0 || conditionID > cvServerIDAdder ||
		lockID < 0 || lockID > lockServerIDAdder)
	{
		strcpy(ack, "-1");
		return 1;
	}

	if (lockID != cvServerList[conditionID].waitLock)
	{
		strcpy(ack, "-1");
		return 1;
	}

	int index = 0;

	cvServerList[conditionID].msgQueue->Remove();

	if(cvServerList[conditionID].msgQueue->IsEmpty()){
		cvServerList[conditionID].waitLock = -1;
	}

	int signalMachineID = *((int *)cvServerList[conditionID].destMachineIDQueue->Remove());
	acquireServerLock(signalMachineID, lockID);
	
	strcpy(ack, "1");
	outPktHdr.to = signalMachineID;                                     
	outMailHdr.to = signalMachineID;
	outMailHdr.from = 0;
	outMailHdr.length = strlen(ack) + 1;
	postOffice->Send(outPktHdr, outMailHdr, ack);

	strcpy(ack, "1");

	return 1;
}

IX.
int BroadcastCV(conditionID, lockID, idOfMachine){

	while (!(cvServerList[conditionID].msgQueue->IsEmpty())){
		SignalCV(conditionID, lockID, idOfMachine);
	}
	return 1;
}

X.
CreateMV(name, idOfMachine)
{
	for (int i = 1; i < mvServerIDAdder; i++){
		if (mvServerList[i].nameOfMV != NULL){
			if (strcmp(mvServerList[i].nameOfMV, name) == 0){
				sprintf(ack, "%d", i);
				mvServerList[i].inUse++;
				return;
			}
		}
	}

	if (mvServerIDAdder >= MV_MAX_COUNT){
		strcpy(ack, "-1");
		return;
	}

	mvServerList[mvServerIDAdder].inUse = 1;

	mvServerList[mvServerIDAdder].nameOfMV = new char[40];
	strcpy(mvServerList[mvServerIDAdder].nameOfMV, name);

	sprintf(ack, "%d", mvServerIDAdder);
	mvServerIDAdder++;
	return;
}

XI.
DestroyMV(idOfMV, idOfMachine)
{
	if (idOfMV < 0 || idOfMV > mvServerIDAdder)
	{
		strcpy(ack, "-1");
		return;
	}

	mvServerList[idOfMV].inUse--;
	if (mvServerList[idOfMV].inUse == 0){
		mvServerList[idOfMV].size = -1;
		mvServerList[idOfMV].mv = NULL;
		mvServerList[idOfMV].nameOfMV = NULL;
	}
	strcpy(ack, "1");
	
	return;
}

XII.
GetMV(idOfMV, idOfMachine)
{
	if (idOfMV < 0 || idOfMV > mvServerIDAdder)
	{
		strcpy(ack, "-1");
		return;
	}

	int value = mvServerList[idOfMV].mv;
	sprintf(ack, "%d", value);
	return;
}

XIII.
SetMV(idOfMV, value, machineID)
{
	if (idOfMV < 0 || idOfMV > mvServerIDAdder)
	{
		strcpy(ack, "-1");
		return;
	}

	mvServerList[idOfMV].mv = value;
	strcpy(ack, "1");
	return;
}

======================================================================================================================================
======================================================================================================================================
IV. Implementation ======================================================================================================================================
======================================================================================================================================
+Files modified
	exception.cc
	syscall.h
	system.h
	system.cc
	addrspace.h
	addrspace.cc
	swapfile
	nettest.cc

+Files added
+Data structure added
	-In file nettest.cc
		struct ServerLock
		struct ServerCV
		struct ServerMV

+Data structure modified
+Functions added
	-In file nettest.cc
		createServerLock();
		acquireServerLock();
		releaseServerLock();
		destroyServerLock();
		CreateCV();
		DestroyCV();
		WaitCV();
		SignalCV();
		BroadcastCV();
		CreateMV();
		DestroyMV();
		GetMV();
		SetMV();
		parsingRequest();
		doServer();
		
+Functions modified
	-In file exception.cc		
		CreateLock();
		DestroyLock();
		Acquire();
		Release();
		CreateCondition();
		DestroyCondition();
		Signal();
		Wait();
		Broadcast();
		CreateMonitor();
		DestroyMonitor();
		GetMonitorVal();
		SetMonitorVal();

	-In file nettest.cc
		MailTest();

======================================================================================================================================
======================================================================================================================================
V. Testing
======================================================================================================================================
======================================================================================================================================
TESTS FOR VM (in vm directory): -matmult2.c, tester.c
To compile: gmake
To run: nachos -x ../test/(filename) -P ("RAND" or "FIFO") -rs (some integer)


matmult2.c:
Tests two instances of matmult with 2 fork calls.

#define Dim 	20	/* sum total of the arrays doesn't fit in 
			 * physical memory 
			 */
	int A[Dim][Dim];
	int B[Dim][Dim];
	int C[Dim][Dim];
	
	int D[Dim][Dim];
	int E[Dim][Dim];
	int F[Dim][Dim];

void mm1()
{
	

	int i, j, k;

    for (i = 0; i < Dim; i++)		/* first initialize the matrices */
	for (j = 0; j < Dim; j++) {
	     A[i][j] = i;
	     B[i][j] = j;
	     C[i][j] = 0;
	}

    for (i = 0; i < Dim; i++)		/* then multiply them together */
	for (j = 0; j < Dim; j++)
            for (k = 0; k < Dim; k++)
		 C[i][j] += A[i][k] * B[k][j];
    Exit(C[Dim-1][Dim-1]);		/* and then we're done */
}

void mm2()
{

	int i, j, k;

    for (i = 0; i < Dim; i++)		/* first initialize the matrices */
	for (j = 0; j < Dim; j++) {
	     D[i][j] = i;
	     E[i][j] = j;
	     F[i][j] = 0;
	}

    for (i = 0; i < Dim; i++)		/* then multiply them together */
	for (j = 0; j < Dim; j++)
            for (k = 0; k < Dim; k++)
		 F[i][j] += D[i][k] * E[k][j];
    Exit(F[Dim-1][Dim-1]);		/* and then we're done */
}

int
main()
{
    Fork(mm1); 
	Fork(mm2);
	Exit(0);
}

tester.c:
Does 8 alternating Exec calls on matmult and Fork calls on a function that calls Exec on matmult 

 void test();

int main() {

	test();
}

void test4()
{
	Exec("../test/matmult", 40);
	Exit(0);
}

void test(){
	
  
  Fork(test4);
  Exec("../test/matmult", 40);
   Fork(test4);
  Exec("../test/matmult", 40);
   Fork(test4);
  Exec("../test/matmult", 40);
   Fork(test4);
  Exec("../test/matmult", 40);

  Exit(0);
}

TESTS FOR NETWORKING (network directory): - networktest.c
to compile: gmake
//Basic Interaction Testing
to run : 
SERVER: nachos -m 0 -server
CLIENT 1: nachos -m [client id] -client //Mainly tested with client id = 1
CLIENT 2: nachos -m [other client id] -client2 //Mainly tested with other client id = 2

//(main)
int id = CreateLock();
	int id2, cv_id, mv_id;
	Acquire(id);
	Release(id);
	DestroyLock(id);

	id2 = CreateLock();
	cv_id = CreateCondition();
	DestroyCondition(cv_id);

	mv_id = CreateMonitor();
	DestroyMonitor(mv_id);

//Synch Testing

//(TestSuite())
int i;
	int cv;
	int l2;
	int mv;
	int value;

	/* Lock Testing - Create a lock for each client - only iterate on 0th lock*/
	int lock = CreateLock();

	Write("Starting Client.\n", 20, ConsoleOutput);

	Acquire(0);

	for (i = 0; i < 100000; i++);

	Release(0);

	for (i = 0; i < 100000; i++);

	/* Condition Testing - Create a Condition for each client - only iterate on 0th condition*/
	cv = CreateCondition();
	l2 = CreateLock();

	Signal(0, 0);
	Wait(0, 0);
	Signal(0, 0);

	Signal(0, 0);
	Wait(0, 0);
	Broadcast(0, 0);

	for (i = 0; i < 100000; i++);

	/* Condition Testing - Create a Condition for each client - only iterate on 0th condition*/
	mv = CreateMonitor();

	SetMonitorVal(mv, 1);
	value = GetMonitorVal(mv);
	IntPrint(value);

	for (i = 0; i < 100000; i++);

	DestroyLock(lock);
	DestroyCondition(cv);
	DestroyLock(l2);
	DestroyMonitor(mv);
======================================================================================================================================
======================================================================================================================================
VI. Discussion
======================================================================================================================================
======================================================================================================================================

Part 3:
+Experiment expectation
	When a client utilizes remote procedure calls to make a request to the server, the server retrieves the request and processes it. The system call is designed for the client to make a request over to the server and wait for the server’s response, after the server has parsed the message of the client’s request. 

+Experiment result
	The result designed specific to a test case is expected to be outputted. 

+Explanation 
	The server and remote procedure calls are designed so that they are capable of making the server parse the message of request from a client to properly deliver the correct response to the client.

 

